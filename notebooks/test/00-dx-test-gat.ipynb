{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "709e5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sales_forecasting.config as config\n",
    "import sales_forecasting.models.train as train_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "919749a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "25\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import sales_forecasting.models.model as model\n",
    "\n",
    "print(len(list((model.GATGCNLSTM(4, 16).parameters()))))\n",
    "print(len(list((model.GCNLSTMBaseline(4, 16).parameters()))))\n",
    "print(len(list((model.LSTMBaseline(4, 16).parameters()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "858b00e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATGCNLSTM has 241 parameters\n",
      "GCNLSTMBaseline has 193 parameters\n",
      "LSTMBaseline has 165 parameters\n"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    \"GATGCNLSTM\": model.GATGCNLSTM(4, 4),\n",
    "    \"GCNLSTMBaseline\": model.GCNLSTMBaseline(4, 4),\n",
    "    \"LSTMBaseline\": model.LSTMBaseline(4, 4),\n",
    "}\n",
    "\n",
    "for name, m in model_dict.items():\n",
    "    total_params = sum(p.numel() for p in m.parameters())\n",
    "    print(f\"{name} has {total_params} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86b79d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GATGCNLSTM parameter breakdown:\n",
      "gat.att: 4 parameters\n",
      "gat.bias: 4 parameters\n",
      "gat.lin_l.weight: 16 parameters\n",
      "gat.lin_l.bias: 4 parameters\n",
      "gat.lin_r.weight: 16 parameters\n",
      "gat.lin_r.bias: 4 parameters\n",
      "gcnlstm.w_c_i: 4 parameters\n",
      "gcnlstm.b_i: 4 parameters\n",
      "gcnlstm.w_c_f: 4 parameters\n",
      "gcnlstm.b_f: 4 parameters\n",
      "gcnlstm.b_c: 4 parameters\n",
      "gcnlstm.w_c_o: 4 parameters\n",
      "gcnlstm.b_o: 4 parameters\n",
      "gcnlstm.conv_x_i.bias: 4 parameters\n",
      "gcnlstm.conv_x_i.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_h_i.bias: 4 parameters\n",
      "gcnlstm.conv_h_i.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_x_f.bias: 4 parameters\n",
      "gcnlstm.conv_x_f.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_h_f.bias: 4 parameters\n",
      "gcnlstm.conv_h_f.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_x_c.bias: 4 parameters\n",
      "gcnlstm.conv_x_c.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_h_c.bias: 4 parameters\n",
      "gcnlstm.conv_h_c.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_x_o.bias: 4 parameters\n",
      "gcnlstm.conv_x_o.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_h_o.bias: 4 parameters\n",
      "gcnlstm.conv_h_o.lins.0.weight: 16 parameters\n",
      "linear.weight: 4 parameters\n",
      "linear.bias: 1 parameters\n",
      "\n",
      "GCNLSTMBaseline parameter breakdown:\n",
      "gcnlstm.w_c_i: 4 parameters\n",
      "gcnlstm.b_i: 4 parameters\n",
      "gcnlstm.w_c_f: 4 parameters\n",
      "gcnlstm.b_f: 4 parameters\n",
      "gcnlstm.b_c: 4 parameters\n",
      "gcnlstm.w_c_o: 4 parameters\n",
      "gcnlstm.b_o: 4 parameters\n",
      "gcnlstm.conv_x_i.bias: 4 parameters\n",
      "gcnlstm.conv_x_i.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_h_i.bias: 4 parameters\n",
      "gcnlstm.conv_h_i.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_x_f.bias: 4 parameters\n",
      "gcnlstm.conv_x_f.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_h_f.bias: 4 parameters\n",
      "gcnlstm.conv_h_f.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_x_c.bias: 4 parameters\n",
      "gcnlstm.conv_x_c.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_h_c.bias: 4 parameters\n",
      "gcnlstm.conv_h_c.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_x_o.bias: 4 parameters\n",
      "gcnlstm.conv_x_o.lins.0.weight: 16 parameters\n",
      "gcnlstm.conv_h_o.bias: 4 parameters\n",
      "gcnlstm.conv_h_o.lins.0.weight: 16 parameters\n",
      "linear.weight: 4 parameters\n",
      "linear.bias: 1 parameters\n",
      "\n",
      "LSTMBaseline parameter breakdown:\n",
      "lstm.weight_ih_l0: 64 parameters\n",
      "lstm.weight_hh_l0: 64 parameters\n",
      "lstm.bias_ih_l0: 16 parameters\n",
      "lstm.bias_hh_l0: 16 parameters\n",
      "fc.weight: 4 parameters\n",
      "fc.bias: 1 parameters\n"
     ]
    }
   ],
   "source": [
    "for model_name, m in model_dict.items():\n",
    "    print(f\"\\n{model_name} parameter breakdown:\")\n",
    "    for name, param in m.named_parameters():\n",
    "        print(f\"{name}: {param.numel()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65b5d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch_geometric.nn\n",
    "from torch_geometric_temporal.nn.recurrent import GConvLSTM\n",
    "\n",
    "\n",
    "class LSTMBaseline(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # predict scalar target\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, window_size, F]\n",
    "        out, _ = self.lstm(x)  # out: [B, window_size, hidden_size]\n",
    "        out = out[:, -1, :]  # take output of last timestep: [B, hidden_size]\n",
    "        out = self.fc(out)  # [B, 1]\n",
    "        return out.squeeze(-1)  # [B]\n",
    "\n",
    "\n",
    "class GCNLSTMBaseline(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, K=1):\n",
    "        super().__init__()\n",
    "        self.gcnlstm = GConvLSTM(in_channels=input_size, out_channels=hidden_size, K=K)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, h=None, c=None):\n",
    "        # x: [window_size, N, F]\n",
    "        # edge_index: [window_size, 2, E]\n",
    "        # edge_weight: [window_size, E]\n",
    "        # h: [N, hidden_size]\n",
    "        # c: [N, hidden_size]\n",
    "\n",
    "        window_size, N, F = x.shape\n",
    "        for t in range(window_size):\n",
    "            # Pass previous hidden states (if any)\n",
    "            h, c = self.gcnlstm(\n",
    "                x[t, :, :], edge_index[t, :, :], edge_weight[t, :], h, c\n",
    "            )\n",
    "        out = self.linear(h)\n",
    "        return out.squeeze(-1), (h, c)\n",
    "\n",
    "\n",
    "class GATGCNLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, K=1):\n",
    "        super().__init__()\n",
    "        self.gat = torch_geometric.nn.conv.GATv2Conv(\n",
    "            in_channels=input_size,\n",
    "            out_channels=input_size,\n",
    "        )\n",
    "        self.gcnlstm = GConvLSTM(in_channels=input_size, out_channels=hidden_size, K=K)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, h=None, c=None):\n",
    "        # x: [window_size, N, F]\n",
    "        # edge_index: [window_size, 2, E]\n",
    "        # edge_weight: [window_size, E]\n",
    "        # h: [N, hidden_size]\n",
    "        # c: [N, hidden_size]\n",
    "\n",
    "        window_size, N, F = x.shape\n",
    "        for t in range(window_size):\n",
    "            # Apply GAT to get edge weights\n",
    "            (_, (e_index, attention_weights)) = self.gat(\n",
    "                x=x[t, :, :],\n",
    "                edge_index=edge_index[t, :, :],\n",
    "                return_attention_weights=True,\n",
    "            )\n",
    "            # Pass previous hidden states (if any)\n",
    "            h, c = self.gcnlstm(\n",
    "                x[t, :, :], e_index, attention_weights.squeeze(-1), h, c\n",
    "            )\n",
    "        out = self.linear(h)\n",
    "        return out.squeeze(-1), (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80db333b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUBaseline(\n",
      "  (gru): GRU(4, 4, batch_first=True)\n",
      "  (fc): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "GRUBaseline now has 125 parameters\n"
     ]
    }
   ],
   "source": [
    "# Replace LSTM with GRU in the baseline model\n",
    "class GRUBaseline(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # predict scalar target\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, window_size, F]\n",
    "        out, _ = self.gru(x)  # out: [B, window_size, hidden_size]\n",
    "        out = out[:, -1, :]  # take output of last timestep: [B, hidden_size]\n",
    "        out = self.fc(out)  # [B, 1]\n",
    "        return out.squeeze(-1)  # [B]\n",
    "\n",
    "\n",
    "# Update existing instances to use the new class\n",
    "m = GRUBaseline(4, 4)\n",
    "model_dict[\"GRUBaseline\"] = m\n",
    "\n",
    "# quick sanity check\n",
    "print(m)\n",
    "print(f\"GRUBaseline now has {sum(p.numel() for p in m.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aed8cb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNLSTMBaseline: GCNGRUBaseline(\n",
      "  (gconvgru): GConvGRU(\n",
      "    (conv_x_z): ChebConv(4, 4, K=1, normalization=sym)\n",
      "    (conv_h_z): ChebConv(4, 4, K=1, normalization=sym)\n",
      "    (conv_x_r): ChebConv(4, 4, K=1, normalization=sym)\n",
      "    (conv_h_r): ChebConv(4, 4, K=1, normalization=sym)\n",
      "    (conv_x_h): ChebConv(4, 4, K=1, normalization=sym)\n",
      "    (conv_h_h): ChebConv(4, 4, K=1, normalization=sym)\n",
      "  )\n",
      "  (linear): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "GCNLSTMBaseline has 125 parameters\n",
      "GATGCNLSTM: GATGCNGRU(\n",
      "  (gat): GATv2Conv(4, 4, heads=1)\n",
      "  (gconvgru): GConvGRU(\n",
      "    (conv_x_z): ChebConv(4, 4, K=1, normalization=sym)\n",
      "    (conv_h_z): ChebConv(4, 4, K=1, normalization=sym)\n",
      "    (conv_x_r): ChebConv(4, 4, K=1, normalization=sym)\n",
      "    (conv_h_r): ChebConv(4, 4, K=1, normalization=sym)\n",
      "    (conv_x_h): ChebConv(4, 4, K=1, normalization=sym)\n",
      "    (conv_h_h): ChebConv(4, 4, K=1, normalization=sym)\n",
      "  )\n",
      "  (linear): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "GATGCNLSTM has 173 parameters\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "\n",
    "\n",
    "class GCNGRUBaseline(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, K=1):\n",
    "        super().__init__()\n",
    "        self.gconvgru = GConvGRU(in_channels=input_size, out_channels=hidden_size, K=K)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, h=None):\n",
    "        # x: [window_size, N, F]\n",
    "        window_size, N, F = x.shape\n",
    "        for t in range(window_size):\n",
    "            h = self.gconvgru(x[t, :, :], edge_index[t, :, :], edge_weight[t, :], h)\n",
    "        out = self.linear(h)\n",
    "        return out.squeeze(-1), h\n",
    "\n",
    "\n",
    "class GATGCNGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, K=1):\n",
    "        super().__init__()\n",
    "        self.gat = torch_geometric.nn.conv.GATv2Conv(\n",
    "            in_channels=input_size,\n",
    "            out_channels=input_size,\n",
    "        )\n",
    "        self.gconvgru = GConvGRU(in_channels=input_size, out_channels=hidden_size, K=K)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, h=None):\n",
    "        # x: [window_size, N, F]\n",
    "        window_size, N, F = x.shape\n",
    "        for t in range(window_size):\n",
    "            (_, (e_index, attention_weights)) = self.gat(\n",
    "                x=x[t, :, :],\n",
    "                edge_index=edge_index[t, :, :],\n",
    "                return_attention_weights=True,\n",
    "            )\n",
    "            h = self.gconvgru(x[t, :, :], e_index, attention_weights.squeeze(-1), h)\n",
    "        out = self.linear(h)\n",
    "        return out.squeeze(-1), h\n",
    "\n",
    "\n",
    "# Replace the existing LSTM-based models in the notebook's model_dict\n",
    "model_dict[\"GCNLSTMBaseline\"] = GCNGRUBaseline(4, 4)\n",
    "model_dict[\"GATGCNLSTM\"] = GATGCNGRU(4, 4)\n",
    "\n",
    "# quick sanity checks\n",
    "for name in (\"GCNLSTMBaseline\", \"GATGCNLSTM\"):\n",
    "    m = model_dict[name]\n",
    "    print(f\"{name}: {m}\")\n",
    "    print(f\"{name} has {sum(p.numel() for p in m.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a94fe02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTMBaseline total parameters: 165\n",
      "  lstm.weight_ih_l0: 64\n",
      "  lstm.weight_hh_l0: 64\n",
      "  lstm.bias_ih_l0: 16\n",
      "  lstm.bias_hh_l0: 16\n",
      "  fc.weight: 4\n",
      "  fc.bias: 1\n",
      "\n",
      "GRUBaseline total parameters: 125\n",
      "  gru.weight_ih_l0: 48\n",
      "  gru.weight_hh_l0: 48\n",
      "  gru.bias_ih_l0: 12\n",
      "  gru.bias_hh_l0: 12\n",
      "  fc.weight: 4\n",
      "  fc.bias: 1\n",
      "\n",
      "GCNLSTMBaseline total parameters: 193\n",
      "  gcnlstm.w_c_i: 4\n",
      "  gcnlstm.b_i: 4\n",
      "  gcnlstm.w_c_f: 4\n",
      "  gcnlstm.b_f: 4\n",
      "  gcnlstm.b_c: 4\n",
      "  gcnlstm.w_c_o: 4\n",
      "  gcnlstm.b_o: 4\n",
      "  gcnlstm.conv_x_i.bias: 4\n",
      "  gcnlstm.conv_x_i.lins.0.weight: 16\n",
      "  gcnlstm.conv_h_i.bias: 4\n",
      "  gcnlstm.conv_h_i.lins.0.weight: 16\n",
      "  gcnlstm.conv_x_f.bias: 4\n",
      "  gcnlstm.conv_x_f.lins.0.weight: 16\n",
      "  gcnlstm.conv_h_f.bias: 4\n",
      "  gcnlstm.conv_h_f.lins.0.weight: 16\n",
      "  gcnlstm.conv_x_c.bias: 4\n",
      "  gcnlstm.conv_x_c.lins.0.weight: 16\n",
      "  gcnlstm.conv_h_c.bias: 4\n",
      "  gcnlstm.conv_h_c.lins.0.weight: 16\n",
      "  gcnlstm.conv_x_o.bias: 4\n",
      "  gcnlstm.conv_x_o.lins.0.weight: 16\n",
      "  gcnlstm.conv_h_o.bias: 4\n",
      "  gcnlstm.conv_h_o.lins.0.weight: 16\n",
      "  linear.weight: 4\n",
      "  linear.bias: 1\n",
      "\n",
      "GCNGRUBaseline total parameters: 125\n",
      "  gconvgru.conv_x_z.bias: 4\n",
      "  gconvgru.conv_x_z.lins.0.weight: 16\n",
      "  gconvgru.conv_h_z.bias: 4\n",
      "  gconvgru.conv_h_z.lins.0.weight: 16\n",
      "  gconvgru.conv_x_r.bias: 4\n",
      "  gconvgru.conv_x_r.lins.0.weight: 16\n",
      "  gconvgru.conv_h_r.bias: 4\n",
      "  gconvgru.conv_h_r.lins.0.weight: 16\n",
      "  gconvgru.conv_x_h.bias: 4\n",
      "  gconvgru.conv_x_h.lins.0.weight: 16\n",
      "  gconvgru.conv_h_h.bias: 4\n",
      "  gconvgru.conv_h_h.lins.0.weight: 16\n",
      "  linear.weight: 4\n",
      "  linear.bias: 1\n",
      "\n",
      "GATGCNLSTM total parameters: 241\n",
      "  gat.att: 4\n",
      "  gat.bias: 4\n",
      "  gat.lin_l.weight: 16\n",
      "  gat.lin_l.bias: 4\n",
      "  gat.lin_r.weight: 16\n",
      "  gat.lin_r.bias: 4\n",
      "  gcnlstm.w_c_i: 4\n",
      "  gcnlstm.b_i: 4\n",
      "  gcnlstm.w_c_f: 4\n",
      "  gcnlstm.b_f: 4\n",
      "  gcnlstm.b_c: 4\n",
      "  gcnlstm.w_c_o: 4\n",
      "  gcnlstm.b_o: 4\n",
      "  gcnlstm.conv_x_i.bias: 4\n",
      "  gcnlstm.conv_x_i.lins.0.weight: 16\n",
      "  gcnlstm.conv_h_i.bias: 4\n",
      "  gcnlstm.conv_h_i.lins.0.weight: 16\n",
      "  gcnlstm.conv_x_f.bias: 4\n",
      "  gcnlstm.conv_x_f.lins.0.weight: 16\n",
      "  gcnlstm.conv_h_f.bias: 4\n",
      "  gcnlstm.conv_h_f.lins.0.weight: 16\n",
      "  gcnlstm.conv_x_c.bias: 4\n",
      "  gcnlstm.conv_x_c.lins.0.weight: 16\n",
      "  gcnlstm.conv_h_c.bias: 4\n",
      "  gcnlstm.conv_h_c.lins.0.weight: 16\n",
      "  gcnlstm.conv_x_o.bias: 4\n",
      "  gcnlstm.conv_x_o.lins.0.weight: 16\n",
      "  gcnlstm.conv_h_o.bias: 4\n",
      "  gcnlstm.conv_h_o.lins.0.weight: 16\n",
      "  linear.weight: 4\n",
      "  linear.bias: 1\n",
      "\n",
      "GATGCNGRU total parameters: 173\n",
      "  gat.att: 4\n",
      "  gat.bias: 4\n",
      "  gat.lin_l.weight: 16\n",
      "  gat.lin_l.bias: 4\n",
      "  gat.lin_r.weight: 16\n",
      "  gat.lin_r.bias: 4\n",
      "  gconvgru.conv_x_z.bias: 4\n",
      "  gconvgru.conv_x_z.lins.0.weight: 16\n",
      "  gconvgru.conv_h_z.bias: 4\n",
      "  gconvgru.conv_h_z.lins.0.weight: 16\n",
      "  gconvgru.conv_x_r.bias: 4\n",
      "  gconvgru.conv_x_r.lins.0.weight: 16\n",
      "  gconvgru.conv_h_r.bias: 4\n",
      "  gconvgru.conv_h_r.lins.0.weight: 16\n",
      "  gconvgru.conv_x_h.bias: 4\n",
      "  gconvgru.conv_x_h.lins.0.weight: 16\n",
      "  gconvgru.conv_h_h.bias: 4\n",
      "  gconvgru.conv_h_h.lins.0.weight: 16\n",
      "  linear.weight: 4\n",
      "  linear.bias: 1\n"
     ]
    }
   ],
   "source": [
    "# instantiate all 6 model classes and print per-parameter breakdown\n",
    "all_models = {\n",
    "    \"LSTMBaseline\": LSTMBaseline(4, 4),\n",
    "    \"GRUBaseline\": GRUBaseline(4, 4),\n",
    "    \"GCNLSTMBaseline\": GCNLSTMBaseline(4, 4),\n",
    "    \"GCNGRUBaseline\": GCNGRUBaseline(4, 4),\n",
    "    \"GATGCNLSTM\": GATGCNLSTM(4, 4),\n",
    "    \"GATGCNGRU\": GATGCNGRU(4, 4),\n",
    "}\n",
    "\n",
    "for name, m in all_models.items():\n",
    "    total = sum(p.numel() for p in m.parameters())\n",
    "    print(f\"\\n{name} total parameters: {total}\")\n",
    "    for pname, p in m.named_parameters():\n",
    "        print(f\"  {pname}: {p.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41527d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import replace\n",
    "\n",
    "base = config.TrainingConfig()\n",
    "tc = replace(\n",
    "    base,\n",
    "    lr=0.0055,\n",
    "    batch_size=8,\n",
    "    window_size=3,\n",
    "    hidden_size=32,\n",
    "    K=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61380a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 1.1464 | Val Loss: 1.3608 | Val RMSE: 1.1665\n",
      " --> Best model saved at epoch 1\n",
      "Epoch 2/100 | Train Loss: 1.1183 | Val Loss: 1.3470 | Val RMSE: 1.1606\n",
      " --> Best model saved at epoch 2\n",
      "Epoch 3/100 | Train Loss: 1.0922 | Val Loss: 1.3314 | Val RMSE: 1.1538\n",
      " --> Best model saved at epoch 3\n",
      "Epoch 4/100 | Train Loss: 1.0566 | Val Loss: 1.3625 | Val RMSE: 1.1673\n",
      "Epoch 5/100 | Train Loss: 1.0203 | Val Loss: 1.4432 | Val RMSE: 1.2013\n",
      "Epoch 6/100 | Train Loss: 0.9863 | Val Loss: 1.5235 | Val RMSE: 1.2343\n",
      "Epoch 7/100 | Train Loss: 0.9633 | Val Loss: 1.5984 | Val RMSE: 1.2643\n",
      "Epoch 8/100 | Train Loss: 0.9168 | Val Loss: 1.5013 | Val RMSE: 1.2253\n",
      "Epoch 9/100 | Train Loss: 0.8397 | Val Loss: 1.5316 | Val RMSE: 1.2376\n",
      "Epoch 10/100 | Train Loss: 0.7936 | Val Loss: 1.5539 | Val RMSE: 1.2465\n",
      "Epoch 11/100 | Train Loss: 0.7386 | Val Loss: 1.5407 | Val RMSE: 1.2413\n",
      "Epoch 12/100 | Train Loss: 0.7004 | Val Loss: 1.5407 | Val RMSE: 1.2412\n",
      "Epoch 13/100 | Train Loss: 0.6574 | Val Loss: 1.4036 | Val RMSE: 1.1847\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 15:16:42 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/10/28 15:16:53 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/28 15:16:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 1.0961 | Val Loss: 0.8603 | Val RMSE: 0.9275\n",
      " --> Best model saved at epoch 1\n",
      "Epoch 2/100 | Train Loss: 1.0545 | Val Loss: 0.8278 | Val RMSE: 0.9098\n",
      " --> Best model saved at epoch 2\n",
      "Epoch 3/100 | Train Loss: 1.0245 | Val Loss: 0.8192 | Val RMSE: 0.9051\n",
      " --> Best model saved at epoch 3\n",
      "Epoch 4/100 | Train Loss: 1.0054 | Val Loss: 0.8762 | Val RMSE: 0.9361\n",
      "Epoch 5/100 | Train Loss: 0.9649 | Val Loss: 0.8140 | Val RMSE: 0.9022\n",
      " --> Best model saved at epoch 5\n",
      "Epoch 6/100 | Train Loss: 0.9181 | Val Loss: 0.8638 | Val RMSE: 0.9294\n",
      "Epoch 7/100 | Train Loss: 0.8581 | Val Loss: 0.7898 | Val RMSE: 0.8887\n",
      " --> Best model saved at epoch 7\n",
      "Epoch 8/100 | Train Loss: 0.8150 | Val Loss: 0.8305 | Val RMSE: 0.9113\n",
      "Epoch 9/100 | Train Loss: 0.7575 | Val Loss: 0.8229 | Val RMSE: 0.9071\n",
      "Epoch 10/100 | Train Loss: 0.7210 | Val Loss: 0.8293 | Val RMSE: 0.9107\n",
      "Epoch 11/100 | Train Loss: 0.6977 | Val Loss: 0.8817 | Val RMSE: 0.9390\n",
      "Epoch 12/100 | Train Loss: 0.6452 | Val Loss: 0.9215 | Val RMSE: 0.9599\n",
      "Epoch 13/100 | Train Loss: 0.6338 | Val Loss: 0.8902 | Val RMSE: 0.9435\n",
      "Epoch 14/100 | Train Loss: 0.6090 | Val Loss: 0.9879 | Val RMSE: 0.9939\n",
      "Epoch 15/100 | Train Loss: 0.5979 | Val Loss: 0.8585 | Val RMSE: 0.9266\n",
      "Epoch 16/100 | Train Loss: 0.5858 | Val Loss: 1.0084 | Val RMSE: 1.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 15:18:03 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 | Train Loss: 0.5717 | Val Loss: 0.9347 | Val RMSE: 0.9668\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 15:18:13 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/28 15:18:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 1.1255 | Val Loss: 0.9809 | Val RMSE: 0.9904\n",
      " --> Best model saved at epoch 1\n",
      "Epoch 2/100 | Train Loss: 1.0853 | Val Loss: 1.0009 | Val RMSE: 1.0005\n",
      "Epoch 3/100 | Train Loss: 1.0830 | Val Loss: 0.9996 | Val RMSE: 0.9998\n",
      "Epoch 4/100 | Train Loss: 1.0545 | Val Loss: 0.9941 | Val RMSE: 0.9970\n",
      "Epoch 5/100 | Train Loss: 1.0425 | Val Loss: 0.9786 | Val RMSE: 0.9892\n",
      " --> Best model saved at epoch 5\n",
      "Epoch 6/100 | Train Loss: 1.0151 | Val Loss: 1.0034 | Val RMSE: 1.0017\n",
      "Epoch 7/100 | Train Loss: 0.9766 | Val Loss: 0.9848 | Val RMSE: 0.9924\n",
      "Epoch 8/100 | Train Loss: 0.9645 | Val Loss: 0.9652 | Val RMSE: 0.9825\n",
      " --> Best model saved at epoch 8\n",
      "Epoch 9/100 | Train Loss: 0.8874 | Val Loss: 0.9807 | Val RMSE: 0.9903\n",
      "Epoch 10/100 | Train Loss: 0.8342 | Val Loss: 1.0286 | Val RMSE: 1.0142\n",
      "Epoch 11/100 | Train Loss: 0.7830 | Val Loss: 0.9941 | Val RMSE: 0.9971\n",
      "Epoch 12/100 | Train Loss: 0.7636 | Val Loss: 1.0750 | Val RMSE: 1.0368\n",
      "Epoch 13/100 | Train Loss: 0.7362 | Val Loss: 1.0052 | Val RMSE: 1.0026\n",
      "Epoch 14/100 | Train Loss: 0.7153 | Val Loss: 1.0807 | Val RMSE: 1.0396\n",
      "Epoch 15/100 | Train Loss: 0.6815 | Val Loss: 1.0170 | Val RMSE: 1.0085\n",
      "Epoch 16/100 | Train Loss: 0.6486 | Val Loss: 1.0554 | Val RMSE: 1.0273\n",
      "Epoch 17/100 | Train Loss: 0.6076 | Val Loss: 1.0670 | Val RMSE: 1.0329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 15:19:54 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 | Train Loss: 0.5875 | Val Loss: 1.0446 | Val RMSE: 1.0220\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 15:20:04 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/28 15:20:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 1.1308 | Val Loss: 0.5662 | Val RMSE: 0.7525\n",
      " --> Best model saved at epoch 1\n",
      "Epoch 2/100 | Train Loss: 1.1009 | Val Loss: 0.5486 | Val RMSE: 0.7407\n",
      " --> Best model saved at epoch 2\n",
      "Epoch 3/100 | Train Loss: 1.0861 | Val Loss: 0.5357 | Val RMSE: 0.7319\n",
      " --> Best model saved at epoch 3\n",
      "Epoch 4/100 | Train Loss: 1.0882 | Val Loss: 0.5565 | Val RMSE: 0.7460\n",
      "Epoch 5/100 | Train Loss: 1.0864 | Val Loss: 0.5308 | Val RMSE: 0.7286\n",
      " --> Best model saved at epoch 5\n",
      "Epoch 6/100 | Train Loss: 1.0578 | Val Loss: 0.5215 | Val RMSE: 0.7221\n",
      " --> Best model saved at epoch 6\n",
      "Epoch 7/100 | Train Loss: 1.0334 | Val Loss: 0.4896 | Val RMSE: 0.6997\n",
      " --> Best model saved at epoch 7\n",
      "Epoch 8/100 | Train Loss: 0.9906 | Val Loss: 0.4102 | Val RMSE: 0.6405\n",
      " --> Best model saved at epoch 8\n",
      "Epoch 9/100 | Train Loss: 0.9666 | Val Loss: 0.3647 | Val RMSE: 0.6039\n",
      " --> Best model saved at epoch 9\n",
      "Epoch 10/100 | Train Loss: 0.9030 | Val Loss: 0.3435 | Val RMSE: 0.5861\n",
      " --> Best model saved at epoch 10\n",
      "Epoch 11/100 | Train Loss: 0.8758 | Val Loss: 0.3379 | Val RMSE: 0.5813\n",
      " --> Best model saved at epoch 11\n",
      "Epoch 12/100 | Train Loss: 0.8459 | Val Loss: 0.3288 | Val RMSE: 0.5734\n",
      " --> Best model saved at epoch 12\n",
      "Epoch 13/100 | Train Loss: 0.8118 | Val Loss: 0.3411 | Val RMSE: 0.5841\n",
      "Epoch 14/100 | Train Loss: 0.7927 | Val Loss: 0.3238 | Val RMSE: 0.5690\n",
      " --> Best model saved at epoch 14\n",
      "Epoch 15/100 | Train Loss: 0.7718 | Val Loss: 0.3194 | Val RMSE: 0.5651\n",
      " --> Best model saved at epoch 15\n",
      "Epoch 16/100 | Train Loss: 0.7526 | Val Loss: 0.3483 | Val RMSE: 0.5902\n",
      "Epoch 17/100 | Train Loss: 0.7140 | Val Loss: 0.3465 | Val RMSE: 0.5887\n",
      "Epoch 18/100 | Train Loss: 0.7070 | Val Loss: 0.3424 | Val RMSE: 0.5852\n",
      "Epoch 19/100 | Train Loss: 0.6865 | Val Loss: 0.3739 | Val RMSE: 0.6114\n",
      "Epoch 20/100 | Train Loss: 0.6684 | Val Loss: 0.3652 | Val RMSE: 0.6043\n",
      "Epoch 21/100 | Train Loss: 0.6418 | Val Loss: 0.3725 | Val RMSE: 0.6103\n",
      "Epoch 22/100 | Train Loss: 0.6500 | Val Loss: 0.3709 | Val RMSE: 0.6090\n",
      "Epoch 23/100 | Train Loss: 0.6223 | Val Loss: 0.4225 | Val RMSE: 0.6500\n",
      "Epoch 24/100 | Train Loss: 0.6065 | Val Loss: 0.3994 | Val RMSE: 0.6320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 15:23:01 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 | Train Loss: 0.5915 | Val Loss: 0.4033 | Val RMSE: 0.6350\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 15:23:12 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/28 15:23:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 1.1139 | Val Loss: 0.8225 | Val RMSE: 0.9069\n",
      " --> Best model saved at epoch 1\n",
      "Epoch 2/100 | Train Loss: 1.0817 | Val Loss: 0.8244 | Val RMSE: 0.9080\n",
      "Epoch 3/100 | Train Loss: 1.0784 | Val Loss: 0.8362 | Val RMSE: 0.9144\n",
      "Epoch 4/100 | Train Loss: 1.0734 | Val Loss: 0.8153 | Val RMSE: 0.9029\n",
      " --> Best model saved at epoch 4\n",
      "Epoch 5/100 | Train Loss: 1.0705 | Val Loss: 0.7979 | Val RMSE: 0.8932\n",
      " --> Best model saved at epoch 5\n",
      "Epoch 6/100 | Train Loss: 1.0225 | Val Loss: 0.7507 | Val RMSE: 0.8664\n",
      " --> Best model saved at epoch 6\n",
      "Epoch 7/100 | Train Loss: 0.9547 | Val Loss: 0.6879 | Val RMSE: 0.8294\n",
      " --> Best model saved at epoch 7\n",
      "Epoch 8/100 | Train Loss: 0.9261 | Val Loss: 0.6855 | Val RMSE: 0.8279\n",
      " --> Best model saved at epoch 8\n",
      "Epoch 9/100 | Train Loss: 0.8712 | Val Loss: 0.6846 | Val RMSE: 0.8274\n",
      " --> Best model saved at epoch 9\n",
      "Epoch 10/100 | Train Loss: 0.8368 | Val Loss: 0.6698 | Val RMSE: 0.8184\n",
      " --> Best model saved at epoch 10\n",
      "Epoch 11/100 | Train Loss: 0.7920 | Val Loss: 0.6847 | Val RMSE: 0.8275\n",
      "Epoch 12/100 | Train Loss: 0.7582 | Val Loss: 0.6969 | Val RMSE: 0.8348\n",
      "Epoch 13/100 | Train Loss: 0.7426 | Val Loss: 0.6958 | Val RMSE: 0.8342\n",
      "Epoch 14/100 | Train Loss: 0.7280 | Val Loss: 0.7245 | Val RMSE: 0.8512\n",
      "Epoch 15/100 | Train Loss: 0.6940 | Val Loss: 0.7067 | Val RMSE: 0.8406\n",
      "Epoch 16/100 | Train Loss: 0.6687 | Val Loss: 0.7274 | Val RMSE: 0.8529\n",
      "Epoch 17/100 | Train Loss: 0.6474 | Val Loss: 0.7581 | Val RMSE: 0.8707\n",
      "Epoch 18/100 | Train Loss: 0.6554 | Val Loss: 0.7305 | Val RMSE: 0.8547\n",
      "Epoch 19/100 | Train Loss: 0.6314 | Val Loss: 0.7418 | Val RMSE: 0.8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 15:26:00 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 | Train Loss: 0.6005 | Val Loss: 0.7334 | Val RMSE: 0.8564\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 15:26:11 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/28 15:26:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean best validation rmse: 0.8817 Â± 0.2171\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from sales_forecasting.utils.experiments import start_run\n",
    "\n",
    "run_name = \"testing_with_plant_edges\"\n",
    "with start_run(run_name=run_name):\n",
    "    mlflow.log_params(asdict(tc))\n",
    "    train_module.run_experiment(tc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
