{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "3e347b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"azminetoushikwasi/supplygraph-supply-chain-planning-using-gnns\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "3f850911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"./supplygraph-supply-chain-planning-using-gnns/versions/2/Raw Dataset/\"\n",
    "\n",
    "# Nodes\n",
    "nodes = pd.read_csv(path + \"Nodes/Nodes.csv\")   \n",
    "edges = pd.read_csv(path + \"Edges/Edges (Plant).csv\")\n",
    "\n",
    "delivery_to_distributor = pd.read_csv(path + \"Temporal Data/Unit/Delivery To distributor.csv\")\n",
    "factory_issue = pd.read_csv(path + \"Temporal Data/Unit/factory issue.csv\")\n",
    "production = pd.read_csv(path + \"Temporal Data/Unit/Production .csv\")\n",
    "sales_order = pd.read_csv(path + \"Temporal Data/Unit/Sales order.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "55d2cc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (220, 41, 4)\n",
      "y shape: (220, 41)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
    "\n",
    "path = \"./supplygraph-supply-chain-planning-using-gnns/versions/2/Raw Dataset/Temporal Data/Unit/\"\n",
    "\n",
    "production = pd.read_csv(path + \"Production .csv\")\n",
    "factory_issue = pd.read_csv(path + \"factory issue.csv\")\n",
    "delivery = pd.read_csv(path + \"Delivery To distributor.csv\")\n",
    "sales_order = pd.read_csv(path + \"Sales order.csv\")\n",
    "\n",
    "products = [col for col in production.columns if col != \"Date\"]\n",
    "product_to_id = {prod: i for i, prod in enumerate(products)}\n",
    "\n",
    "def transform_temporal(df, mapping):\n",
    "    df_no_date = df.drop(columns=[\"Date\"])\n",
    "    return df_no_date.rename(columns=mapping)\n",
    "\n",
    "X_prod = transform_temporal(production, product_to_id)\n",
    "X_issue = transform_temporal(factory_issue, product_to_id)\n",
    "X_delivery = transform_temporal(delivery, product_to_id)\n",
    "X_sales = transform_temporal(sales_order, product_to_id)  \n",
    "\n",
    "X_prod_np = X_prod.to_numpy()\n",
    "X_issue_np = X_issue.to_numpy()\n",
    "X_delivery_np = X_delivery.to_numpy()\n",
    "X_sales_np = X_sales.to_numpy()\n",
    "\n",
    "# shape: [T, N, F] = [time_steps, num_nodes, num_features]\n",
    "X = np.stack([X_prod_np, X_issue_np, X_delivery_np, X_sales_np], axis=-1)\n",
    "\n",
    "y = X_prod_np[1:]       \n",
    "X = X[:-1]\n",
    "\n",
    "print(\"X shape:\", X.shape)  # (T-1, N, 4)\n",
    "print(\"y shape:\", y.shape)  # (T-1, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "3ed04d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_scaled range: -0.43 to 11.69\n",
      "y_scaled range: -0.38 to 8.12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Flatten for scaling: combine time and nodes\n",
    "T, N, F = X.shape\n",
    "X_flat = X.reshape(-1, F)  # shape [T*N, F]\n",
    "y_flat = y.reshape(-1, 1)  # shape [T*N, 1]\n",
    "\n",
    "# Create scalers\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Fit and transform\n",
    "X_scaled_flat = scaler_X.fit_transform(X_flat)\n",
    "y_scaled_flat = scaler_y.fit_transform(y_flat)\n",
    "\n",
    "# Reshape back to original shape\n",
    "X_scaled = X_scaled_flat.reshape(T, N, F)\n",
    "y_scaled = y_scaled_flat.reshape(T, N)\n",
    "\n",
    "print(f\"X_scaled range: {X_scaled.min():.2f} to {X_scaled.max():.2f}\")\n",
    "print(f\"y_scaled range: {y_scaled.min():.2f} to {y_scaled.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "f2671768",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv(\"./supplygraph-supply-chain-planning-using-gnns/versions/2/Raw Dataset/Edges/Edges (Plant).csv\")\n",
    "\n",
    "edges['node1'] = edges['node1'].astype(str)\n",
    "edges['node2'] = edges['node2'].astype(str)\n",
    "\n",
    "edges['node1'] = edges['node1'].map(product_to_id)\n",
    "edges['node2'] = edges['node2'].map(product_to_id)\n",
    "\n",
    "edge_index = edges[['node1', 'node2']].to_numpy().T.astype(np.int64)\n",
    "\n",
    "num_nodes = len(product_to_id)\n",
    "\n",
    "dataset = StaticGraphTemporalSignal(\n",
    "    edge_index=edge_index,\n",
    "    edge_weight=np.ones(edge_index.shape[1]),\n",
    "    features=X_scaled,\n",
    "    targets=y_scaled\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "1f92263b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 41)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "24d1d778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plant</th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1903</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1903</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1903</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>2122</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>2122</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>2122</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>2122</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>2122</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1647 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Plant  node1  node2\n",
       "0      1901     29     25\n",
       "1      1903     23     25\n",
       "2      1903     23     27\n",
       "3      1903     23     32\n",
       "4      1903     23     30\n",
       "...     ...    ...    ...\n",
       "1642   2122     21     19\n",
       "1643   2122     21     12\n",
       "1644   2122      0     19\n",
       "1645   2122      0     12\n",
       "1646   2122     19     12\n",
       "\n",
       "[1647 rows x 3 columns]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "cd9be4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "0397eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import GCLSTM\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GCLSTM(node_features, 64, 1)\n",
    "        self.linear = torch.nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h, c = self.recurrent(x, edge_index, edge_weight)  # Unpack (H, C)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "97c651b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentGCN(node_features=4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "4047ebc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:07<01:21,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/100\n",
      "Train MSE: 0.3698\n",
      "Test MSE: 0.2855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:14<01:09,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/100\n",
      "Train MSE: 0.3103\n",
      "Test MSE: 0.3118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [00:25<01:12,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/100\n",
      "Train MSE: 0.2655\n",
      "Test MSE: 0.2428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [00:32<00:53,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/100\n",
      "Train MSE: 0.2518\n",
      "Test MSE: 0.2523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:39<00:41,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/100\n",
      "Train MSE: 0.2435\n",
      "Test MSE: 0.2444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [00:46<00:35,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60/100\n",
      "Train MSE: 0.2376\n",
      "Test MSE: 0.2428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [00:54<00:24,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70/100\n",
      "Train MSE: 0.2351\n",
      "Test MSE: 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [01:01<00:16,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80/100\n",
      "Train MSE: 0.2330\n",
      "Test MSE: 0.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [01:08<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90/100\n",
      "Train MSE: 0.2308\n",
      "Test MSE: 0.2410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:15<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/100\n",
      "Train MSE: 0.2286\n",
      "Test MSE: 0.2410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_mse(model, dataset):\n",
    "    \"\"\"Calculate MSE on a dataset\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for time, snapshot in enumerate(dataset):\n",
    "            y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "            total_loss += torch.mean((y_hat - snapshot.y) ** 2).item()\n",
    "    model.train()\n",
    "    return total_loss / (time + 1)\n",
    "\n",
    "n_epoch = 100  # Number of epochs\n",
    "for epoch in tqdm(range(n_epoch)):\n",
    "    model.train()\n",
    "    cost = 0\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)  # Model prediction\n",
    "        cost += torch.mean((y_hat - snapshot.y) ** 2)                       # MSE loss\n",
    "    cost = cost / (time + 1)                                                # Average cost\n",
    "    cost.backward()                                                         # Backpropagation\n",
    "    optimizer.step()                                                        # Update weights\n",
    "    optimizer.zero_grad()                                                   # Reset gradients\n",
    "    \n",
    "    # Print metrics every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        train_mse = calculate_mse(model, train_dataset)\n",
    "        test_mse = calculate_mse(model, test_dataset)\n",
    "        print(f\"\\nEpoch {epoch + 1}/{n_epoch}\")\n",
    "        print(f\"Train MSE: {train_mse:.4f}\")\n",
    "        print(f\"Test MSE: {test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb543d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
